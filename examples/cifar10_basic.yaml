# DLtorch Framework
# Author: Junbo Zhao <zhaojb17@mails.tsinghua.edu.cn>.

# An Example Configuration for Training MNIST.

# ---- Basic Settings ----
trainer_type: CNNFinalTrainer      # Type of trainer to use.
device: cuda                       # Device to use. ["cpu","cuda"]
gpus: 0                            # Gpus to use. If a list, for example, "[0, 1]" is given, computation will automatically be paralleled.
epochs: 100                        # Total epoch number to train.
grad_clip: 5.0                     # Grad clip. Won't do clip if it's not given.
eval_no_grad: True                 # Whether to close grad while inference.
early_stop: True                   # Whether use early stop. Remember to set "whether_valid" to be true, if use.
save_as_state_dict: False          # Saving file layout.
path: test                         # Path to save. Will be automatically modified if use "DLtorch test" command.
test_every: 1                      # Number of training epochs to test on testset once.
valid_every: 1                     # Number of training epochs to test on validation set once.
save_every: 50                     # Number of training epochs to save once.
report_every: 0.5                  # Reporting frequency.
portion:                           # How to devide training set into trainset and validation set.
  - 0.9                            # Train set.
  - 0.1                            # Validation set.

# ---- Config for model ----
model: Cifar_resnet18                 # Model to train or test.
model_kwargs: NULL                 # Model kwargs.

# ---- Config for dataset and dataloader ----
dataset: MNIST                     # Dataset to load.
dataset_kwargs:
  dir: E:/DLtorch/DLtorch/datasets/data/Cifar10 # Path
  whether_valid: False                          # If true, the training set will be devided according to portion.
dataloader_kwargs:                              # Dataloader kwargs.
  trainset:
    batch_size: 128
    num_workers: 0
    shuffle: True
    drop_last: False
  testset:
    batch_size: 96
    num_workers: 0
    shuffle: False
    drop_last: False

# ---- Config for objective ----
objective: ClassificationObjective            # Objective type.
objective_kwargs:                             # Objective kwargs.
  criterion_type: CrossEntropyLoss            # Criterion type.
  criterion_kwargs: None                      # Criterion kwargs.

# ---- Config for optimizer ----
optimizer_type: SGD                           # Optimizer type.
optimizer_kwargs:                             # Optimizer kwargs.
  lr: 0.001
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001

# ---- Config for scheduler ----
scheduler: CosineAnnealingLR                  # Scheduler type.
scheduler_kwargs:                             # Scheduler kwargs.
  T_max: 100
  eta_min: 0.0